---
title: "SharkAttack"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The following data sets are provided to analyze Shark Attack.

```{r}
# http://www.huffingtonpost.com/norm-schriever/coming-down-from-shark-we_b_3740495.html
suppressMessages(library(readr))
suppressMessages(library(tidyr))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
# attack location, how many people in the area, water realted env variables, date, time
SAdata <- read_csv("Shark_Attack_Data_4-7-2016.csv",col_names=TRUE,n_max=5897)
SharkSpecies <- tbl_df(read_csv("Shark_Species_Data_4-7-2016.csv"))
Sharks <- read_csv("Sharks_4-7-2016.csv")
```

## Analyze area, location

Note that "Unprovoked attacks" are defined as incidents where an attack on a live human occurs in the sharkâ€™s natural habitat with no human provocation of the shark.

```{r}
SA_tab <- SAdata[1:19] 
SA_tab %>% select(`Case Number`,Date,Year,Location,Area,Country) %>% 
  group_by(Location,Area,Country) %>% summarize(n=n()) %>% 
  filter(is.na(Area)) %>% View()
SA_tab %>% group_by(Location) %>% select(`Case Number`,Date,Year,Area) %>%
  summarize(n=n())
```

# include plots

```{r worldmap}
library("ggmap")
library(maptools)
library(maps)
visited <- c("SFO", "Chennai", "London", "Melbourne")
ll.visited <- geocode(visited)
visit.x <- ll.visited$lon
visit.y <- ll.visited$lat
#USING MAPS
map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
points(visit.x,visit.y, col="red", pch=16)
```

A section of geocoding code.

```{r geocoding}
#### This script uses RCurl and RJSONIO to download data from Google's API:
#### Latitude, longitude, location type (see explanation at the end), formatted address
#### Notice ther is a limit of 2,500 calls per day
library(bitops) 
library(RCurl)
library(RJSONIO)
library(plyr)
 
url <- function(address, return.call = "json", sensor = "false") {
 root <- "http://maps.google.com/maps/api/geocode/"
 u <- paste(root, return.call, "?address=", address, "&sensor=", sensor, sep = "")
 return(URLencode(u))
}
 
geoCode <- function(address,verbose=FALSE) {
 if(verbose) cat(address,"\n")
 u <- url(address)
 doc <- getURL(u)
 x <- fromJSON(doc,simplify = FALSE)
 if(x$status=="OK") {
 lat <- x$results[[1]]$geometry$location$lat
 lng <- x$results[[1]]$geometry$location$lng
 location_type <- x$results[[1]]$geometry$location_type
 formatted_address <- x$results[[1]]$formatted_address
 return(c(lat, lng, location_type, formatted_address))
 } else {
 return(c(NA,NA,NA, NA))
 }
}
```

Let's try a record of shark attack data.

```{r}
##Test with a single address
address <- geoCode("The White House, Washington, DC")
address
#[1] "38.8976831"  lat
#[2] "-77.0364972" lon
#[3] "APPROXIMATE"
#[4] "The White House, 1600 Pennsylvania Avenue Northwest, Washington, D.C., DC 20500, USA"
 
# Use plyr to getgeocoding for a vector
address <- c("The White House, Washington, DC","The Capitol, Washington, DC")
locations <- ldply(address, function(x) geoCode(x))
names(locations) <- c("lat","lon","location_type", "forAddress")

map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
points(as.numeric(locations$lon),as.numeric(locations$lat), 
       col="red", pch=16)
 
#Location type, for more info check here: https://developers.google.com/maps/documentation/directions/
#"ROOFTOP" indicates that the returned result is a precise geocode for which we have location information accurate down to street address precision.
#RANGE_INTERPOLATED" indicates that the returned result reflects an approximation (usually on a road) interpolated between two precise points (such as intersections). Interpolated results are generally returned when rooftop geocodes are unavailable for a street address.
#GEOMETRIC_CENTER" indicates that the returned result is the geometric center of a result such as a polyline (for example, a street) or polygon (region).
#APPROXIMATE" indicates that the returned result is approximate.
```

Let's plot the attacks in USA.

```{r}
USA_tab <- SA_tab %>% filter(Country=="USA") %>%
  select(Location,Area,Country) 
if (any( is.na(USA_tab))) {
  USA_tab[is.na(USA_tab)] <- ""
}
address <- do.call(paste, c(USA_tab, sep=" "))
locations <-  ldply(address[1:50], function(x) geoCode(x))
loc <- locations %>% na.omit()

map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
points(as.numeric(loc$V2),as.numeric(loc$V1), col="red", pch=16)

sub("(a+)", "z\\1z", c("abc", "def", "cba a", "aa"), perl=TRUE)
gsub("(a+)", "z\\1z", c("abc", "def", "cba a", "aa"), perl=TRUE)

ts <- c("\x93Southern Wharf\x94 South Carolina USA",
        "Bull\x92s Bay, near Charleston South Carolina USA")
gsub("[\\p{Cc}]","",ts, perl=TRUE)
#str_split (ts, "[\\\]x[\\d]{1,2}", perl=TRUE)

ts <- c("Bridgeport, Fairfield County Connecticut USA",
        "Avalon, Los Angeles County California USA",
        " Hawaii USA", "Palm Beach, Palm Beach County Florida USA",
        "Ocean City (offshore) New Jersey USA",
        "Staten Island New York USA")
locations <-  ldply(ts, function(x) geoCode(x))
names(locations) <- c("lat","lon","location_type", "forAddress")

points(as.numeric(locations$lon),as.numeric(locations$lat), 
       col="red", pch=16)
```

## World Ocean Database
### Extracting NOAA sea temperatures with ncdf4
The demo following the instruction @ http://lukemiller.org/index.php/2014/11/extracting-noaa-sea-surface-temperatures-with-ncdf4/ is coded in the R chunk as follows.
https://crudata.uea.ac.uk/cru/data/temperature/
https://www.nodc.noaa.gov/OC5/SELECT/dbsearch/dbsearch.html

```{r}
source("NOAA_OISST_ncdf4.R")
ssts = extractOISSTdaily("sst.day.mean.2014.v2.nc","daily/lsmask.oisst.v2.nc",lonW=0,lonE=70,latS=-50,latN=20,date1='2014-11-23',date2='2014-11-24')
plotOISST(ssts,2)
```

