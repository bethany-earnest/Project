---
title: "SharkAttack"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The influence of environmental variables on the presence of white sharks: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3712984/

White sharks have been implicated in 346 unprovoked attacks on humans worldwide, of which 102 were fatal since 1839, with a steady increase in the frequency of attacks.

The following data sets are provided to analyze Shark Attack.

```{r}
# http://www.huffingtonpost.com/norm-schriever/coming-down-from-shark-we_b_3740495.html
suppressMessages(library(readr))
suppressMessages(library(tidyr))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(lubridate))
# attack location, how many people in the area, water realted env variables, date, time
SAdata <- read_csv("Shark_Attack_Data_4-7-2016.csv",col_names=TRUE,n_max=5897)
SharkSpecies <- tbl_df(read_csv("Shark_Species_Data_4-7-2016.csv"))
Sharks <- read_csv("Sharks_4-7-2016.csv")
```

## Analyze area, location

Note that "Unprovoked attacks" are defined as incidents where an attack on a live human occurs in the sharkâ€™s natural habitat with no human provocation of the shark.

```{r}
SA_tab <- tbl_df(SAdata[1:19]) 
colnames(SA_tab)[1] <- "CaseNumber"
SA_tab %>% select(CaseNumber,Date,Year,Location,Area,Country) %>% 
  group_by(Location,Area,Country) %>% dplyr::summarize(n=n()) %>% 
  filter(is.na(Area)) %>% View()
SA_tab %>% group_by(Location) %>% select(CaseNumber,Date,Year,Area) %>%
  dplyr::summarize(n=n())
```

# include plots

```{r worldmap}
library("ggmap")
library(maptools)
library(maps)
visited <- c("SFO", "Chennai", "London", "Melbourne")
ll.visited <- geocode(visited)
visit.x <- ll.visited$lon
visit.y <- ll.visited$lat
#USING MAPS
map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
points(visit.x,visit.y, col="red", pch=16)
```

A section of geocoding code.

```{r geocoding}
#### This script uses RCurl and RJSONIO to download data from Google's API:
#### Latitude, longitude, location type (see explanation at the end), formatted address
#### Notice ther is a limit of 2,500 calls per day
library(bitops) 
library(RCurl)
library(RJSONIO)
 
url <- function(address, return.call = "json", sensor = "false") {
 root <- "http://maps.google.com/maps/api/geocode/"
 u <- paste(root, return.call, "?address=", address, "&sensor=", sensor, sep = "")
 return(URLencode(u))
}
 
geoCode <- function(address,verbose=FALSE) {
 if(verbose) cat(address,"\n")
 u <- url(address)
 doc <- getURL(u)
 x <- fromJSON(doc,simplify = FALSE)
 if(x$status=="OK") {
 lat <- x$results[[1]]$geometry$location$lat
 lng <- x$results[[1]]$geometry$location$lng
 location_type <- x$results[[1]]$geometry$location_type
 formatted_address <- x$results[[1]]$formatted_address
 return(c(lat, lng, location_type, formatted_address))
 } else {
 return(c(NA,NA,NA, NA))
 }
}
```

Let's try a record of shark attack data.

```{r}
##Test with a single address
address <- geoCode("The White House, Washington, DC")
address
#[1] "38.8976831"  lat
#[2] "-77.0364972" lon
#[3] "APPROXIMATE"
#[4] "The White House, 1600 Pennsylvania Avenue Northwest, Washington, D.C., DC 20500, USA"
 
# Use plyr to getgeocoding for a vector
address <- c("The White House, Washington, DC","The Capitol, Washington, DC")
locations <- ldply(address, function(x) geoCode(x))
names(locations) <- c("lat","lon","location_type", "forAddress")

map("world", fill=TRUE, col="white", bg="lightblue", 
    ylim=c(-60, 90), mar=c(0,0,0,0))
points(as.numeric(locations$lon),as.numeric(locations$lat), 
       col="red", pch=16)
 
#Location type, for more info check here: https://developers.google.com/maps/documentation/directions/
#"ROOFTOP" indicates that the returned result is a precise geocode for which we have location information accurate down to street address precision.
#RANGE_INTERPOLATED" indicates that the returned result reflects an approximation (usually on a road) interpolated between two precise points (such as intersections). Interpolated results are generally returned when rooftop geocodes are unavailable for a street address.
#GEOMETRIC_CENTER" indicates that the returned result is the geometric center of a result such as a polyline (for example, a street) or polygon (region).
#APPROXIMATE" indicates that the returned result is approximate.
```

Worldside shark attacks.

```{r}
world_tab <- SA_tab %>% select(CaseNumber,Location,Area,Country,Date) %>% na.omit()
address <- do.call(paste, c(select(world_tab,-c(CaseNumber,Date)), sep=" ")) %>%
              iconv(from="CP1252",to="UTF-8")

# run and then save the result
# infile <- "world_lon-lat_SAdata.rds"
# locations <- sapply(address,geocode)
# saveRDS(locations, infile)

infile <- "world_lon-lat_SAdata-1to2532.rds"
read_loc <- t(readRDS(infile))
read_df <- data.frame(world_tab$CaseNumber,matrix(unlist(read_loc),
                                                  nrow=dim(read_loc)[1]))
names(read_df) <- c("CaseNumber","lon","lat")

infile <- "world_lon-lat_SAdata-2533to5032.rds"
read_loc <- t(readRDS(infile))
read_df[2533:5217,2:3] <-data.frame(matrix(unlist(read_loc),nrow=dim(read_loc)[1]))

# Fixed the following locations manually
Inland <- SA_tab %>% filter(Area=="Guam")
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(144.76,13.48)
# one incident inland is Albuquerque aquarium, Albuquerque, NM
# 6 incidents inland are California, CA
# one incident occurred in Destin, Okaloosa County, FL
Inland <- SA_tab[grep("Destin",SA_tab$Location),]
read_df[which(read_df$CaseNumber %in% Inland$CaseNumber)[1],2:3] <- c(-86.5,30.39)
# one incident in 15 miles south of Jones Inlet, which is actually in Long Island
Inland <- SA_tab[grep("Jones Inlet",SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(-73.13,40.79)
# one incident in Sandbridge beach, VA
Inland <- SA_tab[grep("Sandbridge Beach",SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(-75.94,36.72)
# one incident in Gun Beach, Guam
Inland <- SA_tab[grep("Gun Beach",SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(144.8,13.52)
# one incident in Short sand beach
Inland <- SA_tab[grep("Short Sand Beach",SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(-123.87,45.76)
# one incident in Catalina Island, CA
Inland <- SA_tab[grep("West Cove, Catalina Island",SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <- c(-118.42,33.39)
# one incident in 24 km off Santa Catalina Island in the Channel Islands
Inland <- SA_tab[grep("24 km off Santa Catalina Island",
                      SA_tab$Location),]
read_df[which(read_df$CaseNumber==Inland$CaseNumber),2:3] <-
  c(-118.42,33.3833)

# plot world map
map("world", fill=TRUE, col="white", bg="lightblue", 
    ylim=c(-60, 90), mar=c(0,0,0,0))
read_df <- read_df %>% na.omit() 
points(read_df$lon,read_df$lat, col="red", pch=16)

# old approach - seems not working
#locations <- ldply(address,
#                   function(x) geoCode(x))
# loc <- data.frame(world_tab$CaseNumber,world_tab$Date,t(locations)) %>%
#  na.omit()
#colnames(loc) <- c("CaseNumber","day","lat","lon","location_type",
#                   "forAddress")

#map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
#points(as.numeric(loc$lon),as.numeric(loc$lat), col="red", pch=20)
```


Let's plot the attacks in USA.

```{r}
USA_tab <- SA_tab %>% filter(Country=="USA") %>% left_join(read_df) %>% na.omit()

map("world", fill=TRUE, col="white", bg="lightblue", xlim=c(-130,-60),
    ylim=c(20, 50), mar=c(0,0,0,0))
points(USA_tab$lon,USA_tab$lat, col="red", pch=20)
```

## World Ocean Database
### Extracting NOAA sea temperatures with ncdf4
The demo following the instruction @ http://lukemiller.org/index.php/2014/11/extracting-noaa-sea-surface-temperatures-with-ncdf4/ is coded in the R chunk as follows.
http://www.ncdc.noaa.gov/oisst

https://crudata.uea.ac.uk/cru/data/temperature/
https://www.nodc.noaa.gov/OC5/SELECT/dbsearch/dbsearch.html

Retrieve the daily mean of sea surface temperature.

```{r}
source("NOAA_OISST_ncdf4.R")
ssts = extractOISSTdaily("daily/sst.day.mean.2014.v2.nc","daily/lsmask.oisst.v2.nc",lonW=0.125,lonE=359.875,latS=-89.875,latN=89.875,date1='2014-11-23',date2='2014-11-24')
plotOISST(ssts,1)
```

Retrieve the daily mean of sea surface temperature.

```{r}
# lonW=80,lonE=110,latS=17,latN=35 has values
ssts = extractOISSTdaily("daily/sst.day.mean.2015.v2.nc","daily/lsmask.oisst.v2.nc",lonW=80,lonE=110,latS=20,latN=35,date1='2015-09-20',date2='2015-09-21')
plotOISST(ssts,1)
points(98.7,29.94, col="red", pch=16)


day <- 1
any(!is.na(ssts[, ,day]))
with_value <- !is.na(ssts[, ,day])
sst2 <- ssts[, ,day]
mean(sst2[with_value])
```

Apply the algorithm to the shark attack data.

```{r}
mean_temp <- function(loc) {
  lon <- as.numeric(loc[2])
  lat <- as.numeric(loc[3])
  day <- as.Date(loc[1])
    lonarg <- c(floor(lon),ceiling(lon))
    latarg <- c(floor(lat),ceiling(lat))
    ssts = extractOISSTdaily(
                paste0("daily/sst.day.mean.",year(day),".v2.nc"),
                   "daily/lsmask.oisst.v2.nc",
                   lonW=lonarg[1],lonE=lonarg[2],
                    latS=latarg[1],latN=latarg[2],
                         date1=day)
    while(all(is.na(ssts))) {
      lonarg <- lonarg + c(-1,1)*5
      latarg <- latarg + c(-1,1)*5
      ssts = extractOISSTdaily(
             paste0("daily/sst.day.mean.",year(day),".v2.nc"),
                   "daily/lsmask.oisst.v2.nc",
                   lonW=lonarg[1],lonE=lonarg[2],
                    latS=latarg[1],latN=latarg[2],
                         date1=day)
    }
    with_value <- !is.na(ssts)
    mean(ssts[with_value])
}
# remove words after year, before date, convert to 2-digit year
USA_tab$Date<- gsub ("([0-9]*)\\.(.*)$","\\1",USA_tab$Date)
USA_tab$Date <- gsub("(^\\w*\\s*)\\d","1",USA_tab$Date)
USA_tab$Date <- gsub("(.*)-(..)(..)$", "\\1-\\3", USA_tab$Date)

# fixing year 0-68 --> 2000-2068
loc <- USA_tab %>% mutate(cleanDate=as.Date(Date,format="%d-%b-%y")) %>%
  mutate(cleanDate=as.Date(ifelse(cleanDate > "2016-4-30",
                                  format(cleanDate, "19%y-%m-%d"),
                                  format(cleanDate)))) %>% 
  na.omit() %>% filter(year(cleanDate) >= 1981) %>% 
  arrange(cleanDate) %>% select(cleanDate,lon,lat,CaseNumber)

loc$lon <- loc$lon+180
loc$lat <- loc$lat

loc$temp <- apply(loc,1,mean_temp)
write_csv(loc, "USA_LocTemp.csv")
```

